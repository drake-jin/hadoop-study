package wc;

import java.io.IOException;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
/**
 * 
@SourceCode

 
@WorkFlow
1. 리듀스 단에는 모든 맵 태스크들의 출력들이 모아서 키인 단어로 정렬을 하고 같은 단어를 갖는 레코드를 하나로 묶는다.
2. 그래서 각 단어별로 그 단어를 기로 하고 그 단어의 빈도수 리스트를 밸류로 만들어서 리듀스의 입력으로 지정한다.
3. 리듀스는 간단하게 리듀스의 밸류로 들어온 빈도수 리스트를 스캔해서 빈도수를 다 더한 값을 구한다.
4. 리듀스의 출력은 결국 해당 단어가 키로 되어있고 밸류는 그 단어의 총 빈도수가 되고 총 빈도수가 최종 출력물이 된다.

@Feature
 - 리듀스도 맵처럼 여러개의 태스크가 동시에 실행될 수 있기 때문에 병렬처리가 가능하다.
 - 한 대의 서버에서 해시맵을 이용하는 프로그래밍 방식과 비교하자면 병렬처리를 할 때 프레임워크가 궂은일을 알아서 해주기 때문에 프로그래머는 맵과 리듀스만 잘 구현해주면 된다.
 - 궂은일 = 1. 맵 메소드로 들어갈 입력 레코드를 준비해주는 것, 
 		   2. 맵 메소드의 출력 레코드들을 받아서 그것들을 리듀스의 입력 레코드로 만들어주는 것  
 
 **/

public class MyWordCount {
	// 정적 클래스로 선언하여 메모리 낭비를 줄이기 위함입니다. 프레임워크가 이 클래스들의 부모 클래스까지 이름까지 알아야 하는데
	// 그런 인자는 현재 정의되어 있지 않기 때문입니다.
	
	// Mapper <K1, V1, K2, V2>  => Reducer<K2, V2, K3, V3> 가 되는 이유
	// 리소스(출력:K1,V1) -> Mapper(Out:K2,V2) -> Reducer(Out:K3, V3) 
	
	// Map함수에서 사용할 두 개의 변수를 미리 만들어 둔다. 
	// map함수는 입력 키/벨류 페어에 대해 계속적으로 호출되기 때문에 그 안에서 계속적으로 생성해서 사용하게 되면
	// 가비지 컬렉션에 쌓일 객체들이 늘어나게 됩니다.
	private final static LongWritable one = new LongWritable(1);
	private Text word = new Text();
	
	
	// Mapper 의 K1부분과V1이 LongWriteable, Text인 이유는 입력포맷과 관련이 있는데, 일단 어떤 파일이 입력되느냐와 어떤 입력포멧을 사용하느냐에 따라 K1과 V1의 자료형이 결정됩니다.	
	// K2 V2 는 (keyword, count)
	public static class MyMapper extends Mapper<LongWritable, Text, Text, LongWritable>{
		@Override
		protected void map(LongWritable key, Text value, Mapper<LongWritable, Text, Text, LongWritable>.Context context)
				throws IOException, InterruptedException {
			// String, Long 대신에 LongWritable, Text를 쓰는 이유에는 MapReduce프레임워크에서 WritableComparable인터페이스를 지원해야 사용할 수 있습니다.
			// 하지만 String과 Long은 저 인터페이스(MapReduce프레임워크 자체 인터페이스 이기 때문에)가 없어서 Text,LongWritable로 대체되어 사용합니다.
			// Context는 변환된(결과의) 키/벨류 페어에 대해 값을 써줍니다.
			
			super.map(key, value, context);
		}
	}
	
	// Reducer는 프레임 워크에서 최종적으로 출력하는 녀석.
	public static class MyReducer extends Reducer<Text, LongWritable, Text, LongWritable>{
		@Override
		// Iterable은 리스트로 출력하겠다는 것이다. 
		// 마지막 Context arg2를 이용하여 프레임워크로 변환된 키/벨류 페어를 출력할 수 있습니다.
		// 맵의 출력 키/벨류 타입과 리듀스의 입력 키/벨류 타입은 일치해야합니다. 그렇기 때문에 K2/V2는 동일하게 사용되야 합니다.
		protected void reduce(Text arg0, Iterable<LongWritable> arg1,
				Reducer<Text, LongWritable, Text, LongWritable>.Context arg2) throws IOException, InterruptedException {
			super.reduce(arg0, arg1, arg2);
		
		}
		
	}
	}

/*
	main함수에서는 결국 Configuration과 Job 두 클래스의 인스턴스들을 이용해서 이제 수행하려는 잡의 환경을 설정하고 대략 다음과 같은 일을 수행합니다.
	 - 맵,리듀스 클래스가 존재해야한다.
	 - 입력 파일 위치, 출력 디렉토리 지정, 둘다 HDFS상에 있어야 한다.
	 - 입력/출력 포맷 지정, 이에 대해서는 뒤에서 자세히 설명함.
	 - 최종 출력 키와 벨류타입을 지정해야한다 = 리듀서의 출력 키 벨류
	 - 맵의 출력 키와 벨류 = 리듀서의 입력 키와 벨류

*/	
	
	public static void main(String[] args) throw Exception{
		Configuration conf = new Configuration();
		Job job = new Job(conf, "JobName");
		
		job.waitForCompletion(true);
	}

}
